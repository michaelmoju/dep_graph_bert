{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ujson\n",
    "import csv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tnrange as trange\n",
    "from collections import OrderedDict\n",
    "\n",
    "w_dir = %pwd\n",
    "work_dir = os.path.dirname(w_dir) + '/../..'\n",
    "work_dir\n",
    "sys.path.append(work_dir + \"/dep_graph_bert/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dep_graph_bert.dataset_readers.dgb import DgbReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data import TextFieldTensors, Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/moju/data/work/dep_graph_bert/dep_graph_bert/dataset_readers\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers import PretrainedTransformerMismatchedIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_indexers = {'bert': PretrainedTransformerMismatchedIndexer('bert-base-uncased', namespace = 'token')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = DgbReader(token_indexers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='reading instances', max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = reader.read(file_path = \"/media/moju/data/work/dep_graph_bert/acl-14-short-data/test.raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t tokens: TextField of length 42 with text: \n",
      " \t\t[dear,  , justin,  , ,, gray, hoodies, turned, into, leather, jackets, ,, '', ay, !, '', turned,\n",
      "\t\tinto, '', swag, '', ,, u, grew, up, ,, and, we, ', ve, been, here, all, the, way, ., rt, i, u, love,\n",
      "\t\tbieber, ♥]\n",
      " \t\tand TokenIndexers : {'bert': 'PretrainedTransformerMismatchedIndexer'} \n",
      " \t adj_matrix: ArrayField with shape: (42, 42) and dtype: <class 'numpy.float32'>. \n",
      " \t aspect_span: SpanField with spans: (1, 1). \n",
      " \t meta: {'comment_text': \"Dear $T$ , Gray Hoodies turned into Leather Jackets , '' Ay ! '' turned into '' Swag '' , u grew up , and we 've been here all the way . RT i u love Bieber ♥\", 'aspect': 'justin'} \n",
      " \t label: LabelField with label: 1 in namespace: 'labels'.' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = data[1]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.index(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_lengths = text_field.get_padding_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert': {'token_ids': tensor([  101,  6203,  6796,  1010,  3897,  7415,  3111,  2357,  2046,  5898,\n",
       "          17764,  1010,  1005,  1005,  1037,  2100,   999,  1005,  1005,  2357,\n",
       "           2046,  1005,  1005, 25430,  8490,  1005,  1005,  1010,  1057,  3473,\n",
       "           2039,  1010,  1998,  2057,  1005,  2310,  2042,  2182,  2035,  1996,\n",
       "           2126,  1012, 19387,  1045,  1057,  2293, 12170, 22669,  1625,   102]),\n",
       "  'mask': tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True]),\n",
       "  'type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]),\n",
       "  'wordpiece_mask': tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True]),\n",
       "  'offsets': tensor([[ 1,  1],\n",
       "          [-1, -1],\n",
       "          [ 2,  2],\n",
       "          [-1, -1],\n",
       "          [ 3,  3],\n",
       "          [ 4,  4],\n",
       "          [ 5,  6],\n",
       "          [ 7,  7],\n",
       "          [ 8,  8],\n",
       "          [ 9,  9],\n",
       "          [10, 10],\n",
       "          [11, 11],\n",
       "          [12, 13],\n",
       "          [14, 15],\n",
       "          [16, 16],\n",
       "          [17, 18],\n",
       "          [19, 19],\n",
       "          [20, 20],\n",
       "          [21, 22],\n",
       "          [23, 24],\n",
       "          [25, 26],\n",
       "          [27, 27],\n",
       "          [28, 28],\n",
       "          [29, 29],\n",
       "          [30, 30],\n",
       "          [31, 31],\n",
       "          [32, 32],\n",
       "          [33, 33],\n",
       "          [34, 34],\n",
       "          [35, 35],\n",
       "          [36, 36],\n",
       "          [37, 37],\n",
       "          [38, 38],\n",
       "          [39, 39],\n",
       "          [40, 40],\n",
       "          [41, 41],\n",
       "          [42, 42],\n",
       "          [43, 43],\n",
       "          [44, 44],\n",
       "          [45, 45],\n",
       "          [46, 47],\n",
       "          [48, 48]])}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.as_tensor(padding_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
